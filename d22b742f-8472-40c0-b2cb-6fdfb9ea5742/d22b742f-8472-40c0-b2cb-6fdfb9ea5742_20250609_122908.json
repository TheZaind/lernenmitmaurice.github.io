{
  "knowledge_extraction": {
    "format_version": "2.0",
    "micros": [
      {
        "id": "micro_1",
        "title": "DeepSeek-V3: Ein MoE-Modell",
        "knowledge_md": "Hast du dich jemals gefragt, wie riesige Sprachmodelle effizient arbeiten? ü§î\n\nDeepSeek-V3 ist ein fortschrittliches Large Language Model (LLM), das als Mixture-of-Experts (MoE) Modell konzipiert ist. Es besitzt beeindruckende 671 Milliarden Parameter, wobei f√ºr jedes Token nur 37 Milliarden aktiviert werden.\n\nStell dir vor, du hast ein riesiges Team, aber nur die besten Experten f√ºr eine spezifische Aufgabe werden angefordert ‚Äì so arbeitet DeepSeek-V3, um Leistung zu optimieren.",
        "visual_title": "MoE-Architektur verstehen",
        "visual_description_text": "Klicke auf die Experten, um zu sehen, wie DeepSeek-V3 nur die relevantesten aktiviert.",
        "visual_description": {
          "concept": "Mixture-of-Experts (MoE)",
          "description": "Eine schematische Darstellung eines MoE-Modells, bei dem ein Router-Netzwerk eingehende Tokens zu einer Auswahl von Experten (kleinere neuronale Netze) leitet. Visualisiere 671B Gesamtparameter, aber nur 37B aktivierte Parameter pro Token, um den Effizienzgewinn zu zeigen.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht das Konzept von Mixture-of-Experts (MoE) und seine Anwendung in DeepSeek-V3.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "graph",
          "structure": {
            "nodes": [
              {
                "id": "center",
                "label": "DeepSeek-V3: Ein MoE-Modell"
              },
              {
                "id": "aspect1",
                "label": "Aspekt 1"
              },
              {
                "id": "aspect2",
                "label": "Aspekt 2"
              },
              {
                "id": "aspect3",
                "label": "Aspekt 3"
              }
            ],
            "edges": [
              {
                "from": "center",
                "to": "aspect1"
              },
              {
                "from": "center",
                "to": "aspect2"
              },
              {
                "from": "center",
                "to": "aspect3"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine schematische Darstellung eines MoE-Modells, bei dem ein Router-Netzwerk eingehende Tokens zu einer Auswahl von Experten (kleinere neuronale Netze) leitet. Visualisiere 671B Gesamtparameter, aber nur 37B aktivierte Parameter pro Token, um den Effizienzgewinn zu zeigen."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele Parameter werden in DeepSeek-V3 pro Token aktiviert?",
          "options": [
            "671 Milliarden",
            "37 Milliarden",
            "14.8 Billionen",
            "2.788 Millionen"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 hat 671 Milliarden Parameter insgesamt, aber nur 37 Milliarden werden f√ºr jedes Token aktiviert, was die Effizienz steigert."
        }
      },
      {
        "id": "micro_2",
        "title": "MLA & DeepSeekMoE: Effizienz-Kerne",
        "knowledge_md": "Wie erreicht DeepSeek-V3 Spitzenleistung zu geringen Kosten? üí°\n\nDeepSeek-V3 setzt auf bew√§hrte Architekturen: Multi-head Latent Attention (MLA) f√ºr effiziente Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training. Diese wurden bereits in DeepSeek-V2 erfolgreich validiert.\n\nStell dir MLA wie eine optimierte Suchmaschine vor, die schnell relevante Infos findet, und DeepSeekMoE wie ein Team, das Ressourcen optimal teilt, um Kosten zu senken.",
        "visual_title": "Architektur-Bausteine",
        "visual_description_text": "Erkunde, wie MLA und DeepSeekMoE zusammenarbeiten, um DeepSeek-V3 zu optimieren.",
        "visual_description": {
          "concept": "MLA & DeepSeekMoE",
          "description": "Eine Infografik, die Multi-head Latent Attention (MLA) als Mechanismus f√ºr effiziente Inferenz und DeepSeekMoE als Ansatz f√ºr kosteng√ºnstiges Training darstellt. Zeige Pfeile, die ihre Funktionen und den Beitrag zur Gesamtleistung illustrieren.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die Rolle von Multi-head Latent Attention (MLA) und DeepSeekMoE in der Architektur von DeepSeek-V3.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "MLA & DeepSeekMoE: Effizienz-Kerne",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Infografik, die Multi-head Latent Attention (MLA) als Mechanismus f√ºr effiziente Inferenz und DeepSeekMoE als Ansatz f√ºr kosteng√ºnstiges Training darstellt. Zeige Pfeile, die ihre Funktionen und den Beitrag zur Gesamtleistung illustrieren."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Architekturkomponente von DeepSeek-V3 ist f√ºr effiziente Inferenz verantwortlich?",
          "options": [
            "DeepSeekMoE",
            "Multi-head Latent Attention (MLA)",
            "FP8 Mixed Precision Training",
            "DualPipe Algorithmus"
          ],
          "correct_answer": 1,
          "explanation": "Multi-head Latent Attention (MLA) wird in DeepSeek-V3 f√ºr effiziente Inferenz eingesetzt."
        }
      },
      {
        "id": "micro_3",
        "title": "Strategien f√ºr mehr Leistung",
        "knowledge_md": "Was macht DeepSeek-V3 noch leistungsf√§higer? ‚ú®\n\nDeepSeek-V3 implementiert zwei innovative Strategien: Eine hilfsverlustfreie Lastverteilung minimiert Leistungseinbu√üen. Zudem verbessert ein Multi-Token Prediction (MTP) Trainingsziel die Gesamtperformance.\n\nDie Lastverteilung sorgt f√ºr effizienten Betrieb. MTP hilft dem Modell, mehrere W√∂rter gleichzeitig vorherzusagen, was es kl√ºger macht und die Inferenz beschleunigen kann.",
        "visual_title": "Intelligente Optimierungen",
        "visual_description_text": "Entdecke, wie DeepSeek-V3 durch Lastverteilung und Multi-Token Prediction noch besser wird.",
        "visual_description": {
          "concept": "Auxiliary-loss-free Load Balancing & Multi-Token Prediction",
          "description": "Zwei separate, interaktive Diagramme. Eines zeigt die Lastverteilung ohne Hilfsverlust, das andere visualisiert, wie Multi-Token Prediction die Vorhersagef√§higkeit des Modells verbessert, indem es mehrere Tokens gleichzeitig ber√ºcksichtigt.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die Vorteile der hilfsverlustfreien Lastverteilung und des Multi-Token Prediction (MTP) Trainingsziels in DeepSeek-V3.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "timeline",
          "structure": {
            "timeline": {
              "title": "Strategien f√ºr mehr Leistung",
              "sections": [
                {
                  "period": "Phase 1",
                  "events": [
                    "Einf√ºhrung",
                    "Grundlagen"
                  ]
                },
                {
                  "period": "Phase 2",
                  "events": [
                    "Vertiefung",
                    "Anwendung"
                  ]
                },
                {
                  "period": "Phase 3",
                  "events": [
                    "Meisterschaft",
                    "Integration"
                  ]
                }
              ]
            }
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei separate, interaktive Diagramme. Eines zeigt die Lastverteilung ohne Hilfsverlust, das andere visualisiert, wie Multi-Token Prediction die Vorhersagef√§higkeit des Modells verbessert, indem es mehrere Tokens gleichzeitig ber√ºcksichtigt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche der folgenden Strategien wird in DeepSeek-V3 zur Verbesserung der Modellleistung eingesetzt?",
          "options": [
            "Tensor-Parallelisierung",
            "Auxiliary-loss-free Load Balancing",
            "Single-Token Prediction",
            "Manuelle Datenbereinigung"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 implementiert eine hilfsverlustfreie Strategie zur Lastverteilung und ein Multi-Token Prediction Trainingsziel, um die Modellleistung zu verbessern."
        }
      },
      {
        "id": "micro_4",
        "title": "FP8: Training mit Pr√§zision",
        "knowledge_md": "Wie wird DeepSeek-V3 so effizient trainiert? üöÄ\n\nDeepSeek-V3 setzt auf FP8 Mixed Precision Training. Diese Methode nutzt niedrigere Pr√§zision f√ºr Berechnungen und Speicherung, was das Training beschleunigt und den GPU-Speicherverbrauch reduziert.\n\nStell dir vor, du kannst eine komplexe Zeichnung mit weniger, aber pr√§zisen Strichen anfertigen. FP8 erm√∂glicht √§hnliche Effizienz beim Training riesiger Modelle.",
        "visual_title": "FP8 im Detail",
        "visual_description_text": "Sieh, wie FP8 Mixed Precision Training die Effizienz revolutioniert.",
        "visual_description": {
          "concept": "FP8 Mixed Precision Training",
          "description": "Eine Animation, die den Unterschied zwischen Standard-Pr√§zision und FP8 Mixed Precision bei Berechnungen und Speicherung zeigt. Visualisiere, wie FP8 zu schnellerem Training und geringerem Speicherverbrauch f√ºhrt.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht das Konzept und die Vorteile von FP8 Mixed Precision Training f√ºr die Effizienz des LLM-Trainings.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "FP8: Training mit Pr√§zision",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Animation, die den Unterschied zwischen Standard-Pr√§zision und FP8 Mixed Precision bei Berechnungen und Speicherung zeigt. Visualisiere, wie FP8 zu schnellerem Training und geringerem Speicherverbrauch f√ºhrt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Vorteile bietet FP8 Mixed Precision Training f√ºr DeepSeek-V3?",
          "options": [
            "Erh√∂hte GPU-Speichernutzung",
            "Verlangsamtes Training",
            "Beschleunigtes Training und reduzierter GPU-Speicherverbrauch",
            "Ausschlie√ülich f√ºr Inferenz genutzt"
          ],
          "correct_answer": 2,
          "explanation": "FP8 Mixed Precision Training erm√∂glicht sowohl beschleunigtes Training als auch reduzierten GPU-Speicherverbrauch."
        }
      },
      {
        "id": "micro_5",
        "title": "Trainings-Framework-Innovationen",
        "knowledge_md": "Welche Tricks stecken im Trainings-Framework von DeepSeek-V3? üõ†Ô∏è\n\nDas Framework nutzt den DualPipe-Algorithmus f√ºr effiziente Pipeline-Parallelisierung, der Kommunikationszeiten durch √úberlappung mit Berechnungen verbirgt. Auch wurden Cross-Node-Kommunikations-Kernels optimiert.\n\nDenk an DualPipe wie an eine Fabrik, in der verschiedene Schritte gleichzeitig ablaufen und Wartezeiten minimiert werden, um die Produktion zu beschleunigen.",
        "visual_title": "DualPipe & Kommunikation",
        "visual_description_text": "Erfahre, wie DualPipe und optimierte Kommunikation das Training beschleunigen.",
        "visual_description": {
          "concept": "DualPipe & Communication Overlap",
          "description": "Ein Flussdiagramm, das den DualPipe-Algorithmus darstellt, wie er Pipeline-Bubbles reduziert und Kommunikation mit Berechnungen √ºberlappt. Zeige auch die Rolle von Cross-Node-Kommunikations-Kernels bei der Nutzung von InfiniBand/NVLink.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die Optimierungen im Trainings-Framework von DeepSeek-V3, insbesondere DualPipe und Kommunikations√ºberlappung.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Trainings-Framework-Innovationen",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Flussdiagramm, das den DualPipe-Algorithmus darstellt, wie er Pipeline-Bubbles reduziert und Kommunikation mit Berechnungen √ºberlappt. Zeige auch die Rolle von Cross-Node-Kommunikations-Kernels bei der Nutzung von InfiniBand/NVLink."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welcher Algorithmus wird in DeepSeek-V3 f√ºr effiziente Pipeline-Parallelisierung eingesetzt?",
          "options": [
            "SinglePipe",
            "DualPipe",
            "TriplePipe",
            "QuadPipe"
          ],
          "correct_answer": 1,
          "explanation": "Der DualPipe-Algorithmus wurde f√ºr effiziente Pipeline-Parallelisierung in DeepSeek-V3 entwickelt."
        }
      },
      {
        "id": "micro_6",
        "title": "Stabiles Pre-Training",
        "knowledge_md": "Wie stabil ist das Training eines solch riesigen Modells? üßò‚Äç‚ôÄÔ∏è\n\nDeepSeek-V3 wurde auf 14.8 Billionen hochwertigen Tokens vortrainiert. Dieser Pre-Training-Prozess war bemerkenswert stabil, ohne irreparable Verlustspitzen oder Rollbacks.\n\nStell dir vor, du baust ein riesiges Geb√§ude, und jeder Schritt verl√§uft reibungslos, ohne dass du jemals etwas neu bauen musst. Das ist die Stabilit√§t des DeepSeek-V3 Pre-Trainings.",
        "visual_title": "Pre-Training-Stabilit√§t",
        "visual_description_text": "Visualisiere die Stabilit√§t des Pre-Training-Prozesses von DeepSeek-V3.",
        "visual_description": {
          "concept": "Stable Pre-training",
          "description": "Eine Zeitlinie oder ein Diagramm, das den Verlust w√§hrend des Pre-Trainings von DeepSeek-V3 darstellt, um zu zeigen, dass es keine 'irrecoverable loss spikes' oder Rollbacks gab. Zeige die 14.8T Tokens als Input.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die Stabilit√§t und den Umfang des Pre-Training-Prozesses von DeepSeek-V3.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "timeline",
          "structure": {
            "timeline": {
              "title": "Stabiles Pre-Training",
              "sections": [
                {
                  "period": "Phase 1",
                  "events": [
                    "Einf√ºhrung",
                    "Grundlagen"
                  ]
                },
                {
                  "period": "Phase 2",
                  "events": [
                    "Vertiefung",
                    "Anwendung"
                  ]
                },
                {
                  "period": "Phase 3",
                  "events": [
                    "Meisterschaft",
                    "Integration"
                  ]
                }
              ]
            }
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Zeitlinie oder ein Diagramm, das den Verlust w√§hrend des Pre-Trainings von DeepSeek-V3 darstellt, um zu zeigen, dass es keine 'irrecoverable loss spikes' oder Rollbacks gab. Zeige die 14.8T Tokens als Input."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele hochwertige Tokens wurden f√ºr das Pre-Training von DeepSeek-V3 verwendet?",
          "options": [
            "37 Milliarden",
            "671 Milliarden",
            "14.8 Billionen",
            "2.788 Millionen"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 wurde auf 14.8 Billionen hochwertigen und diversen Tokens vortrainiert."
        }
      },
      {
        "id": "micro_7",
        "title": "Kontext & Post-Training",
        "knowledge_md": "Wie wird DeepSeek-V3 noch intelligenter und menschen√§hnlicher? üß†\n\nNach dem Pre-Training wurde die Kontextl√§nge von DeepSeek-V3 in zwei Stufen auf 32K und dann auf 128K erweitert. Anschlie√üend erfolgte ein Post-Training (SFT und RL), um es an menschliche Pr√§ferenzen anzupassen.\n\nDas Modell lernt zuerst Grundlagen, dann wie man lange, komplexe Gespr√§che f√ºhrt und menschliche Nuancen versteht.",
        "visual_title": "Modell-Verfeinerung",
        "visual_description_text": "Verfolge die Schritte der Kontextl√§ngenerweiterung und des Post-Trainings.",
        "visual_description": {
          "concept": "Context Length Extension & Post-training",
          "description": "Ein zweistufiger Prozess: Zuerst die Erweiterung der Kontextl√§nge von 32K auf 128K. Dann die Post-Training-Phase mit Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL), um das Modell an menschliche Pr√§ferenzen anzupassen und Reasoning-F√§higkeiten zu destillieren.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die Bedeutung der Kontextl√§ngenerweiterung und des Post-Trainings (SFT, RL) f√ºr DeepSeek-V3.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Kontext & Post-Training",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein zweistufiger Prozess: Zuerst die Erweiterung der Kontextl√§nge von 32K auf 128K. Dann die Post-Training-Phase mit Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL), um das Modell an menschliche Pr√§ferenzen anzupassen und Reasoning-F√§higkeiten zu destillieren."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Auf welche maximale Kontextl√§nge wurde DeepSeek-V3 in der zweiten Stufe erweitert?",
          "options": [
            "32K",
            "64K",
            "128K",
            "256K"
          ],
          "correct_answer": 2,
          "explanation": "Die maximale Kontextl√§nge von DeepSeek-V3 wurde in der ersten Stufe auf 32K und in der zweiten Stufe auf 128K erweitert."
        }
      },
      {
        "id": "micro_8",
        "title": "Kosten-Effizienz des Trainings",
        "knowledge_md": "Wie viel kostet es, ein Top-LLM wie DeepSeek-V3 zu trainieren? üí∏\n\nDeepSeek-V3 wurde mit optimierten Algorithmen und Frameworks trainiert, was zu geringen Kosten f√ºhrte. Das gesamte Training kostete nur 2.788 Millionen GPU-Stunden, was etwa $5.576 Millionen entspricht.\n\nDas Pre-Training auf 14.8 Billionen Tokens kostete 2.664 Millionen H800 GPU-Stunden.",
        "visual_title": "Trainingskosten im √úberblick",
        "visual_description_text": "Sieh dir die beeindruckend niedrigen Trainingskosten von DeepSeek-V3 an.",
        "visual_description": {
          "concept": "Training Costs",
          "description": "Eine Infografik, die die Aufschl√ºsselung der Trainingskosten von DeepSeek-V3 zeigt: Pre-Training (2664K H800 GPU Hours), Context Extension (119K), Post-Training (5K), und die Gesamtkosten in GPU-Stunden und USD ($5.576M).",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die Gesamtkosten und die Aufschl√ºsselung des Trainings von DeepSeek-V3.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Kosten-Effizienz des Trainings",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Infografik, die die Aufschl√ºsselung der Trainingskosten von DeepSeek-V3 zeigt: Pre-Training (2664K H800 GPU Hours), Context Extension (119K), Post-Training (5K), und die Gesamtkosten in GPU-Stunden und USD ($5.576M)."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie hoch waren die Gesamtkosten f√ºr das Training von DeepSeek-V3 (ohne Forschungskosten)?",
          "options": [
            "$2.788 Millionen",
            "$5.328 Millionen",
            "$5.576 Millionen",
            "$0.238 Millionen"
          ],
          "correct_answer": 2,
          "explanation": "Die Gesamtkosten f√ºr das Training von DeepSeek-V3 beliefen sich auf $5.576 Millionen."
        }
      },
      {
        "id": "micro_9",
        "title": "DeepSeek-V3: Spitzenleistung",
        "knowledge_md": "Wie gut schneidet DeepSeek-V3 im Vergleich ab? üèÜ\n\nDeepSeek-V3-Base ist das st√§rkste Open-Source-Basismodell, besonders in Code und Mathematik. Die Chat-Version √ºbertrifft andere Open-Source-Modelle und erreicht vergleichbare Leistung wie f√ºhrende Closed-Source-Modelle.\n\nDeepSeek-V3-Base ist der Champion im Programmieren und Rechnen. Die Chat-Version kann locker mit den besten kommerziellen Modellen wie GPT-4o mithalten.",
        "visual_title": "Benchmark-Ergebnisse",
        "visual_description_text": "Vergleiche die Leistung von DeepSeek-V3 mit anderen Top-Modellen.",
        "visual_description": {
          "concept": "Performance Evaluation",
          "description": "Ein Balkendiagramm oder eine Vergleichstabelle, die die Leistung von DeepSeek-V3-Base (besonders in Code und Mathematik) und der Chat-Version im Vergleich zu anderen Open-Source-Modellen und f√ºhrenden Closed-Source-Modellen (GPT-4o, Claude-3.5-Sonnet) darstellt.",
          "interaction_type": "click_explore",
          "learning_goal": "Der Benutzer versteht die herausragende Leistung von DeepSeek-V3 im Vergleich zu anderen Modellen, insbesondere in Code und Mathematik.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "DeepSeek-V3: Spitzenleistung",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Balkendiagramm oder eine Vergleichstabelle, die die Leistung von DeepSeek-V3-Base (besonders in Code und Mathematik) und der Chat-Version im Vergleich zu anderen Open-Source-Modellen und f√ºhrenden Closed-Source-Modellen (GPT-4o, Claude-3.5-Sonnet) darstellt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "In welchen Bereichen hat sich DeepSeek-V3-Base als besonders starkes Open-Source-Modell erwiesen?",
          "options": [
            "Sprach√ºbersetzung und Bilderkennung",
            "Code und Mathematik",
            "Musikkomposition und Videobearbeitung",
            "Finanzanalyse und Wettervorhersage"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3-Base hat sich als das st√§rkste Open-Source-Basismodell erwiesen, besonders in den Bereichen Code und Mathematik."
        }
      }
    ],
    "metadata": {
      "original_pdf_chapters_count": 1,
      "total_micros_generated": 9
    }
  },
  "metadata": {
    "source_file": "temp\\d22b742f-8472-40c0-b2cb-6fdfb9ea5742.pdf",
    "generation_date": "2025-06-09T12:29:08.758109",
    "source_filename": "d22b742f-8472-40c0-b2cb-6fdfb9ea5742"
  }
}