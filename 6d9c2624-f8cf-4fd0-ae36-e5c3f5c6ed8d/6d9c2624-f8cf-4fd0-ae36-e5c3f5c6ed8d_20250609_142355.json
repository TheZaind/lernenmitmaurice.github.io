{
  "knowledge_extraction": {
    "format_version": "2.0",
    "micros": [
      {
        "id": "micro_1",
        "title": "DeepSeek-V3: Ein MoE-Modell",
        "knowledge_md": "Hast du dich je gefragt, was DeepSeek-V3 so besonders macht? ü§î DeepSeek-V3 ist ein gro√ües Mixture-of-Experts (MoE) Modell mit 671 Milliarden Parametern. F√ºr jedes Token werden davon 37 Milliarden aktiviert. Es ist ein offenes Modell, das die L√ºcke zu Closed-Source-Modellen schlie√üen will.",
        "visual_title": "MoE-Modell-Struktur",
        "visual_description_text": "Klicke, um die Architektur eines MoE-Modells zu erkunden.",
        "visual_description": {
          "concept": "Mixture-of-Experts (MoE)",
          "description": "Eine schematische Darstellung eines gro√üen Sprachmodells, das aus mehreren 'Experten'-Netzwerken besteht. Wenn ein Token verarbeitet wird, werden nur einige dieser Experten aktiviert, was die Effizienz erh√∂ht. Visualisiere 671B Parameter, von denen 37B pro Token aktiv sind.",
          "interaction_type": "click_explore",
          "learning_goal": "Verstehen, was DeepSeek-V3 als MoE-Modell auszeichnet und wie es funktioniert.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "graph",
          "structure": {
            "nodes": [
              {
                "id": "center",
                "label": "DeepSeek-V3: Ein MoE-Modell"
              },
              {
                "id": "aspect1",
                "label": "Aspekt 1"
              },
              {
                "id": "aspect2",
                "label": "Aspekt 2"
              },
              {
                "id": "aspect3",
                "label": "Aspekt 3"
              }
            ],
            "edges": [
              {
                "from": "center",
                "to": "aspect1"
              },
              {
                "from": "center",
                "to": "aspect2"
              },
              {
                "from": "center",
                "to": "aspect3"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine schematische Darstellung eines gro√üen Sprachmodells, das aus mehreren 'Experten'-Netzwerken besteht. Wenn ein Token verarbeitet wird, werden nur einige dieser Experten aktiviert, was die Effizienz erh√∂ht. Visualisiere 671B Parameter, von denen 37B pro Token aktiv sind."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele Parameter werden bei DeepSeek-V3 f√ºr jedes Token aktiviert?",
          "options": [
            "671 Milliarden",
            "37 Milliarden",
            "14.8 Billionen",
            "2.788 Millionen"
          ],
          "correct_answer": 1,
          "explanation": "F√ºr jedes Token werden bei DeepSeek-V3 37 Milliarden Parameter aktiviert, obwohl das Modell insgesamt 671 Milliarden Parameter besitzt."
        }
      },
      {
        "id": "micro_2",
        "title": "Effiziente Architektur: MLA & DeepSeekMoE",
        "knowledge_md": "Wie erreicht DeepSeek-V3 seine starke Leistung und Kosteneffizienz? üí° DeepSeek-V3 nutzt Multi-head Latent Attention (MLA) f√ºr effiziente Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training. Diese Architekturen wurden bereits in DeepSeek-V2 validiert.",
        "visual_title": "Architektur-Grundlagen",
        "visual_description_text": "Klicke, um die Schl√ºsselkomponenten der DeepSeek-V3-Architektur zu sehen.",
        "visual_description": {
          "concept": "MLA und DeepSeekMoE",
          "description": "Zwei Zahnr√§der, die ineinandergreifen. Ein Zahnrad ist mit 'MLA' (Multi-head Latent Attention) beschriftet, das andere mit 'DeepSeekMoE'. Pfeile zeigen, wie sie zusammenarbeiten, um Effizienz und Leistung zu gew√§hrleisten.",
          "interaction_type": "click_explore",
          "learning_goal": "Die architektonischen Grundlagen von DeepSeek-V3 f√ºr Effizienz und Leistung identifizieren.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Effiziente Architektur: MLA & DeepSeekMoE",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei Zahnr√§der, die ineinandergreifen. Ein Zahnrad ist mit 'MLA' (Multi-head Latent Attention) beschriftet, das andere mit 'DeepSeekMoE'. Pfeile zeigen, wie sie zusammenarbeiten, um Effizienz und Leistung zu gew√§hrleisten."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Architekturen werden in DeepSeek-V3 f√ºr effiziente Inferenz und kosteng√ºnstiges Training verwendet?",
          "options": [
            "GPT-4o und Claude-3.5",
            "MLA und DeepSeekMoE",
            "SFT und RL",
            "FP8 und DualPipe"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 verwendet Multi-head Latent Attention (MLA) f√ºr effiziente Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training."
        }
      },
      {
        "id": "micro_3",
        "title": "Leistungssteigerung: Lastausgleich & MTP",
        "knowledge_md": "M√∂chtest du wissen, wie DeepSeek-V3 seine F√§higkeiten weiter verbessert? üöÄ DeepSeek-V3 implementiert zwei Strategien zur Leistungssteigerung. Erstens eine Hilfsverlust-freie Strategie f√ºr Lastausgleich, um Leistungseinbu√üen zu minimieren. Zweitens ein Multi-Token Prediction (MTP) Trainingsziel.",
        "visual_title": "Strategien zur Leistungssteigerung",
        "visual_description_text": "Klicke, um die zwei Hauptstrategien zur Leistungssteigerung zu verstehen.",
        "visual_description": {
          "concept": "Lastausgleich & Multi-Token Prediction",
          "description": "Zwei vertikale Pfeile, die nach oben zeigen. Der linke Pfeil ist mit 'Hilfsverlust-freier Lastausgleich' beschriftet, der rechte mit 'Multi-Token Prediction (MTP)'. Eine Waage symbolisiert den Lastausgleich, ein Stapel von Token das MTP.",
          "interaction_type": "click_explore",
          "learning_goal": "Die zus√§tzlichen Strategien zur Verbesserung der Modellf√§higkeiten von DeepSeek-V3 benennen und ihren Zweck verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Leistungssteigerung: Lastausgleich & MTP",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei vertikale Pfeile, die nach oben zeigen. Der linke Pfeil ist mit 'Hilfsverlust-freier Lastausgleich' beschriftet, der rechte mit 'Multi-Token Prediction (MTP)'. Eine Waage symbolisiert den Lastausgleich, ein Stapel von Token das MTP."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche zwei zus√§tzlichen Strategien werden in DeepSeek-V3 zur Leistungssteigerung eingesetzt?",
          "options": [
            "Kontextl√§ngen-Erweiterung und Post-Training",
            "FP8-Training und DualPipe-Algorithmus",
            "Hilfsverlust-freie Lastausgleichsstrategie und Multi-Token Prediction (MTP) Trainingsziel",
            "SFT und RL"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 nutzt eine Hilfsverlust-freie Strategie f√ºr Lastausgleich und ein Multi-Token Prediction (MTP) Trainingsziel zur Leistungssteigerung."
        }
      },
      {
        "id": "micro_4",
        "title": "Effizientes Training mit FP8 Mixed Precision",
        "knowledge_md": "Wie trainiert DeepSeek-V3 so effizient? ‚ö° DeepSeek-V3 unterst√ºtzt FP8 Mixed Precision Training. Dies ist eine vielversprechende L√∂sung f√ºr effizientes Training, die Trainingsbeschleunigung und reduzierten GPU-Speicherverbrauch erm√∂glicht.",
        "visual_title": "FP8 Training",
        "visual_description_text": "Klicke, um die Vorteile von FP8 Mixed Precision Training zu visualisieren.",
        "visual_description": {
          "concept": "FP8 Mixed Precision Training",
          "description": "Eine Grafik, die eine GPU mit einem 'FP8'-Label zeigt. Zwei Pfeile gehen von der GPU aus: einer nach oben, beschriftet mit 'Schnelleres Training', und einer nach unten, beschriftet mit 'Weniger GPU-Speicher'.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Rolle und die Vorteile des FP8 Mixed Precision Trainings in DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Effizientes Training mit FP8 Mixed Precision",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Grafik, die eine GPU mit einem 'FP8'-Label zeigt. Zwei Pfeile gehen von der GPU aus: einer nach oben, beschriftet mit 'Schnelleres Training', und einer nach unten, beschriftet mit 'Weniger GPU-Speicher'."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Vorteile bietet das FP8 Mixed Precision Training in DeepSeek-V3?",
          "options": [
            "Erh√∂hte Modellgenauigkeit und l√§ngere Trainingszeiten",
            "Beschleunigtes Training und reduzierter GPU-Speicherverbrauch",
            "Bessere Lastausgleichsstrategien und verbesserte Inferenz",
            "Niedrigere Trainingskosten und h√∂here Kontextl√§nge"
          ],
          "correct_answer": 1,
          "explanation": "Das FP8 Mixed Precision Training in DeepSeek-V3 erm√∂glicht sowohl beschleunigtes Training als auch reduzierten GPU-Speicherverbrauch."
        }
      },
      {
        "id": "micro_5",
        "title": "Optimiertes Trainings-Framework",
        "knowledge_md": "Welche cleveren Tricks nutzt DeepSeek-V3 im Trainings-Framework? ‚öôÔ∏è DeepSeek-V3 verwendet den DualPipe-Algorithmus f√ºr effiziente Pipeline-Parallelit√§t, der Kommunikationsaufwand durch √úberlappung mit Berechnung verbirgt. Auch effiziente Cross-Node All-to-All Kommunikations-Kernels werden eingesetzt.",
        "visual_title": "DualPipe-Algorithmus",
        "visual_description_text": "Klicke, um zu sehen, wie DeepSeek-V3 Kommunikation und Berechnung √ºberlappt.",
        "visual_description": {
          "concept": "DualPipe-Algorithmus",
          "description": "Eine Zeitleiste, die zwei parallele Prozesse darstellt: 'Berechnung' und 'Kommunikation'. Die Visualisierung zeigt, wie sich diese Prozesse √ºberlappen, um 'Pipeline-Bubbles' zu minimieren und Effizienz zu maximieren.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Optimierungen im Trainings-Framework von DeepSeek-V3, insbesondere den DualPipe-Algorithmus, erkl√§ren.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Optimiertes Trainings-Framework",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Zeitleiste, die zwei parallele Prozesse darstellt: 'Berechnung' und 'Kommunikation'. Die Visualisierung zeigt, wie sich diese Prozesse √ºberlappen, um 'Pipeline-Bubbles' zu minimieren und Effizienz zu maximieren."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welcher Algorithmus wird in DeepSeek-V3 f√ºr effiziente Pipeline-Parallelit√§t verwendet?",
          "options": [
            "Multi-head Latent Attention (MLA)",
            "DeepSeekMoE",
            "DualPipe",
            "Multi-Token Prediction (MTP)"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 verwendet den DualPipe-Algorithmus f√ºr effiziente Pipeline-Parallelit√§t, der die Kommunikation w√§hrend des Trainings durch √úberlappung mit der Berechnung verbirgt."
        }
      },
      {
        "id": "micro_6",
        "title": "Stabiler Pre-Training-Prozess",
        "knowledge_md": "War das Pre-Training von DeepSeek-V3 eine reibungslose Fahrt? üé¢ DeepSeek-V3 wurde auf 14.8 Billionen hochwertigen und diversen Tokens vortrainiert. Der Pre-Training-Prozess war bemerkenswert stabil.",
        "visual_title": "Pre-Training Stabilit√§t",
        "visual_description_text": "Klicke, um die Stabilit√§t des Pre-Trainings zu visualisieren.",
        "visual_description": {
          "concept": "Stabiles Pre-Training",
          "description": "Eine durchgehende, glatte Linie auf einem Diagramm, die 'Verlust' √ºber 'Trainingsschritte' darstellt, ohne pl√∂tzliche Spitzen oder Einbr√ºche. Ein gr√ºnes H√§kchen symbolisiert 'Keine Rollbacks'.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Stabilit√§t und den Umfang des Pre-Trainings von DeepSeek-V3 beschreiben.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Stabiler Pre-Training-Prozess",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine durchgehende, glatte Linie auf einem Diagramm, die 'Verlust' √ºber 'Trainingsschritte' darstellt, ohne pl√∂tzliche Spitzen oder Einbr√ºche. Ein gr√ºnes H√§kchen symbolisiert 'Keine Rollbacks'."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele Tokens wurden f√ºr das Pre-Training von DeepSeek-V3 verwendet?",
          "options": [
            "37 Milliarden",
            "671 Milliarden",
            "14.8 Billionen",
            "2.788 Millionen"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 wurde auf 14.8 Billionen hochwertigen und diversen Tokens vortrainiert."
        }
      },
      {
        "id": "micro_7",
        "title": "Kontextl√§ngen-Erweiterung & Post-Training",
        "knowledge_md": "Wie wird DeepSeek-V3 nach dem Pre-Training weiter verbessert? üìà Nach dem Pre-Training erfolgte eine zweistufige Kontextl√§ngen-Erweiterung auf 32K und dann auf 128K. Anschlie√üend wurde Post-Training durchgef√ºhrt.",
        "visual_title": "Nach dem Pre-Training",
        "visual_description_text": "Klicke, um die Schritte nach dem Pre-Training zu verstehen.",
        "visual_description": {
          "concept": "Kontextl√§ngen-Erweiterung & Post-Training",
          "description": "Eine Zeitleiste mit drei Phasen: 'Pre-Training', gefolgt von 'Kontextl√§ngen-Erweiterung (32K -> 128K)' und 'Post-Training (SFT & RL)'. Symbole f√ºr Anpassung und Freischaltung des Potenzials.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Schritte der Kontextl√§ngen-Erweiterung und des Post-Trainings von DeepSeek-V3 erkl√§ren.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "timeline",
          "structure": {
            "timeline": {
              "title": "Kontextl√§ngen-Erweiterung & Post-Training",
              "sections": [
                {
                  "period": "Phase 1",
                  "events": [
                    "Einf√ºhrung",
                    "Grundlagen"
                  ]
                },
                {
                  "period": "Phase 2",
                  "events": [
                    "Vertiefung",
                    "Anwendung"
                  ]
                },
                {
                  "period": "Phase 3",
                  "events": [
                    "Meisterschaft",
                    "Integration"
                  ]
                }
              ]
            }
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Zeitleiste mit drei Phasen: 'Pre-Training', gefolgt von 'Kontextl√§ngen-Erweiterung (32K -> 128K)' und 'Post-Training (SFT & RL)'. Symbole f√ºr Anpassung und Freischaltung des Potenzials."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Methoden werden im Post-Training von DeepSeek-V3 angewendet?",
          "options": [
            "Multi-head Latent Attention (MLA) und DeepSeekMoE",
            "FP8 Mixed Precision Training und DualPipe",
            "Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL)",
            "Hilfsverlust-freier Lastausgleich und Multi-Token Prediction (MTP)"
          ],
          "correct_answer": 2,
          "explanation": "Im Post-Training von DeepSeek-V3 werden Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL) angewendet."
        }
      },
      {
        "id": "micro_8",
        "title": "Wirtschaftliche Trainingskosten",
        "knowledge_md": "Wie kosteng√ºnstig ist das Training von DeepSeek-V3 wirklich? üí∞ DeepSeek-V3 zeichnet sich durch au√üergew√∂hnlich wirtschaftliche Trainingskosten aus. Das gesamte Training, inklusive aller Stufen, kostet nur 2.788 Millionen H800 GPU-Stunden.",
        "visual_title": "Kosten√ºbersicht",
        "visual_description_text": "Klicke, um die beeindruckenden Trainingskosten von DeepSeek-V3 zu sehen.",
        "visual_description": {
          "concept": "Trainingskosten",
          "description": "Eine Tabelle, die die Gesamtkosten von DeepSeek-V3 in H800 GPU-Stunden und USD darstellt. Fokus auf die Gesamtsumme von 2.788M GPU-Stunden und $5.576M.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Gesamtkosten und die Effizienz des Trainings von DeepSeek-V3 quantifizieren.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Wirtschaftliche Trainingskosten",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Tabelle, die die Gesamtkosten von DeepSeek-V3 in H800 GPU-Stunden und USD darstellt. Fokus auf die Gesamtsumme von 2.788M GPU-Stunden und $5.576M."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie hoch sind die Gesamtkosten f√ºr das Training von DeepSeek-V3 in H800 GPU-Stunden?",
          "options": [
            "2664K",
            "119K",
            "5K",
            "2788K"
          ],
          "correct_answer": 3,
          "explanation": "Die Gesamtkosten f√ºr das Training von DeepSeek-V3 belaufen sich auf 2.788 Millionen (2788K) H800 GPU-Stunden."
        }
      },
      {
        "id": "micro_9",
        "title": "Leistungsvergleich: Open- vs. Closed-Source",
        "knowledge_md": "Wie schneidet DeepSeek-V3 im Vergleich ab? üèÜ Umfassende Evaluierungen zeigen, dass DeepSeek-V3-Base das st√§rkste verf√ºgbare Open-Source-Basismodell ist, besonders in Code und Mathematik.",
        "visual_title": "DeepSeek-V3 im Vergleich",
        "visual_description_text": "Klicke, um die Position von DeepSeek-V3 im Wettbewerb zu sehen.",
        "visual_description": {
          "concept": "Leistungsvergleich",
          "description": "Ein Podium mit drei Stufen. DeepSeek-V3-Base steht auf der h√∂chsten Stufe, beschriftet mit 'St√§rkstes Open-Source'. Daneben sind Symbole f√ºr Code und Mathematik. Eine weitere Grafik zeigt die Chat-Version im Vergleich zu GPT-4o und Claude-3.5-Sonnet.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Leistung von DeepSeek-V3 im Vergleich zu anderen Open- und Closed-Source-Modellen beurteilen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Leistungsvergleich: Open- vs. Closed-Source",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Podium mit drei Stufen. DeepSeek-V3-Base steht auf der h√∂chsten Stufe, beschriftet mit 'St√§rkstes Open-Source'. Daneben sind Symbole f√ºr Code und Mathematik. Eine weitere Grafik zeigt die Chat-Version im Vergleich zu GPT-4o und Claude-3.5-Sonnet."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "In welchen Bereichen ist DeepSeek-V3-Base besonders stark?",
          "options": [
            "Sprach√ºbersetzung und Bilderkennung",
            "Code und Mathematik",
            "Textzusammenfassung und Stimmungsanalyse",
            "Datenbankmanagement und Netzwerksicherheit"
          ],
          "correct_answer": 1,
          "explanation": "Umfassende Evaluierungen zeigen, dass DeepSeek-V3-Base besonders in Code und Mathematik das st√§rkste verf√ºgbare Open-Source-Basismodell ist."
        }
      }
    ],
    "metadata": {
      "original_pdf_chapters_count": 1,
      "total_micros_generated": 9
    }
  },
  "metadata": {
    "source_file": "temp\\6d9c2624-f8cf-4fd0-ae36-e5c3f5c6ed8d.pdf",
    "generation_date": "2025-06-09T14:23:55.360313",
    "source_filename": "6d9c2624-f8cf-4fd0-ae36-e5c3f5c6ed8d"
  }
}