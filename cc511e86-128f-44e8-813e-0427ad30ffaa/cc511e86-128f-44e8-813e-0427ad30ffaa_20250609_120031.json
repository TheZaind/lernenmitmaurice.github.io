{
  "knowledge_extraction": {
    "format_version": "2.0",
    "micros": [
      {
        "id": "micro_1",
        "title": "DeepSeek-V3: Ein Open-Source Gigant",
        "knowledge_md": "Hast du dich je gefragt, wie Open-Source-LLMs mit den Gro√üen mithalten? üöÄ DeepSeek-V3 ist ein riesiges Mixture-of-Experts (MoE) Modell mit 671 Milliarden Parametern, von denen 37 Milliarden pro Token aktiviert werden. Es wurde entwickelt, um die Grenzen der Open-Source-Modellf√§higkeiten zu erweitern und die L√ºcke zu Closed-Source-Modellen zu schlie√üen.",
        "visual_title": "DeepSeek-V3: Modell√ºbersicht",
        "visual_description_text": "Klicke auf die verschiedenen Bereiche des Modells, um mehr √ºber seine Struktur zu erfahren.",
        "visual_description": {
          "concept": "MoE Modell",
          "description": "Eine schematische Darstellung eines gro√üen Sprachmodells (LLM) als Wolke oder Netzwerk, mit einem hervorgehobenen Bereich, der die 'Mixture-of-Experts' (MoE) Architektur darstellt. Ein kleinerer, leuchtender Bereich innerhalb der MoE-Struktur symbolisiert die '37B aktivierten Parameter pro Token'.",
          "interaction_type": "click_explore",
          "learning_goal": "Die grundlegende Definition und den Umfang von DeepSeek-V3 als MoE-Modell verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "graph",
          "structure": {
            "nodes": [
              {
                "id": "center",
                "label": "DeepSeek-V3: Ein Open-Source Gigant"
              },
              {
                "id": "aspect1",
                "label": "Aspekt 1"
              },
              {
                "id": "aspect2",
                "label": "Aspekt 2"
              },
              {
                "id": "aspect3",
                "label": "Aspekt 3"
              }
            ],
            "edges": [
              {
                "from": "center",
                "to": "aspect1"
              },
              {
                "from": "center",
                "to": "aspect2"
              },
              {
                "from": "center",
                "to": "aspect3"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine schematische Darstellung eines gro√üen Sprachmodells (LLM) als Wolke oder Netzwerk, mit einem hervorgehobenen Bereich, der die 'Mixture-of-Experts' (MoE) Architektur darstellt. Ein kleinerer, leuchtender Bereich innerhalb der MoE-Struktur symbolisiert die '37B aktivierten Parameter pro Token'."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele Parameter werden in DeepSeek-V3 pro Token aktiviert?",
          "options": [
            "671 Milliarden",
            "37 Milliarden",
            "128K",
            "14.8 Billionen"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 ist ein MoE-Modell mit 671B Parametern, von denen 37B f√ºr jeden Token aktiviert werden."
        }
      },
      {
        "id": "micro_2",
        "title": "Effiziente Architektur: MLA & DeepSeekMoE",
        "knowledge_md": "M√∂chtest du wissen, wie DeepSeek-V3 Leistung und Kosten optimiert? ‚öôÔ∏è DeepSeek-V3 nutzt Multi-head Latent Attention (MLA) f√ºr effiziente Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training. Diese Architekturen wurden bereits in DeepSeek-V2 validiert. Sie sind entscheidend, um robuste Modellleistung bei Effizienz zu gew√§hrleisten.",
        "visual_title": "Architektur-Grundlagen",
        "visual_description_text": "Erkunde die Bausteine, die DeepSeek-V3 so effizient machen.",
        "visual_description": {
          "concept": "MLA & DeepSeekMoE",
          "description": "Zwei miteinander verbundene Zahnr√§der oder Bausteine, beschriftet mit 'MLA' und 'DeepSeekMoE'. Pfeile deuten auf 'Effiziente Inferenz' und 'Kosteng√ºnstiges Training'.",
          "interaction_type": "click_explore",
          "learning_goal": "Die zwei Schl√ºsselarchitekturen (MLA, DeepSeekMoE) und deren Vorteile f√ºr DeepSeek-V3 identifizieren.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Effiziente Architektur: MLA & DeepSeekMoE",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei miteinander verbundene Zahnr√§der oder Bausteine, beschriftet mit 'MLA' und 'DeepSeekMoE'. Pfeile deuten auf 'Effiziente Inferenz' und 'Kosteng√ºnstiges Training'."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Architektur wird in DeepSeek-V3 f√ºr kosteng√ºnstiges Training verwendet?",
          "options": [
            "Multi-head Latent Attention (MLA)",
            "DeepSeekMoE",
            "DualPipe",
            "FP8 Mixed Precision"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 nutzt DeepSeekMoE f√ºr kosteng√ºnstiges Training."
        }
      },
      {
        "id": "micro_3",
        "title": "Innovative Strategien: Lastausgleich & MTP",
        "knowledge_md": "Was macht DeepSeek-V3 √ºber seine Basisarchitektur hinaus so besonders? ‚ú® DeepSeek-V3 f√ºhrt zwei neue Strategien ein. Erstens, eine Auxiliary-Loss-Free-Strategie f√ºr Lastausgleich, die Leistungsverluste minimiert. Zweitens, ein Multi-Token Prediction (MTP) Trainingsziel, das die Gesamtleistung auf Benchmarks verbessert.",
        "visual_title": "DeepSeek-V3: Strategien",
        "visual_description_text": "Entdecke die zwei innovativen Strategien, die DeepSeek-V3 verbessern.",
        "visual_description": {
          "concept": "Lastausgleich & MTP",
          "description": "Zwei separate, aber parallel verlaufende Pfade. Der eine Pfad ist mit 'Auxiliary-Loss-Free Lastausgleich' beschriftet und zeigt eine Waage im Gleichgewicht. Der andere Pfad ist mit 'Multi-Token Prediction' beschriftet und zeigt eine Reihe von Tokens, die gleichzeitig verarbeitet werden.",
          "interaction_type": "click_explore",
          "learning_goal": "Die zwei zus√§tzlichen Strategien (Auxiliary-Loss-Free Lastausgleich, Multi-Token Prediction) und deren Zweck in DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "timeline",
          "structure": {
            "timeline": {
              "title": "Innovative Strategien: Lastausgleich & MTP",
              "sections": [
                {
                  "period": "Phase 1",
                  "events": [
                    "Einf√ºhrung",
                    "Grundlagen"
                  ]
                },
                {
                  "period": "Phase 2",
                  "events": [
                    "Vertiefung",
                    "Anwendung"
                  ]
                },
                {
                  "period": "Phase 3",
                  "events": [
                    "Meisterschaft",
                    "Integration"
                  ]
                }
              ]
            }
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei separate, aber parallel verlaufende Pfade. Der eine Pfad ist mit 'Auxiliary-Loss-Free Lastausgleich' beschriftet und zeigt eine Waage im Gleichgewicht. Der andere Pfad ist mit 'Multi-Token Prediction' beschriftet und zeigt eine Reihe von Tokens, die gleichzeitig verarbeitet werden."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welches Ziel verfolgt die Auxiliary-Loss-Free-Strategie in DeepSeek-V3?",
          "options": [
            "Beschleunigung der Inferenz",
            "Minimierung des Leistungsverlusts beim Lastausgleich",
            "Reduzierung des GPU-Speicherverbrauchs",
            "Verbesserung der Kontextl√§nge"
          ],
          "correct_answer": 1,
          "explanation": "Die Auxiliary-Loss-Free-Strategie dient der Minimierung des Leistungsverlusts, der beim Lastausgleich entsteht."
        }
      },
      {
        "id": "micro_4",
        "title": "FP8 Mixed Precision Training",
        "knowledge_md": "Wie erreicht DeepSeek-V3 eine so hohe Trainingseffizienz? ‚ö° DeepSeek-V3 implementiert ein FP8 Mixed Precision Training Framework. Dies erm√∂glicht beschleunigtes Training und reduziert den GPU-Speicherverbrauch. Es ist das erste Mal, dass FP8 auf einem extrem gro√üen Modell validiert wurde.",
        "visual_title": "FP8 Training im Detail",
        "visual_description_text": "Visualisiere, wie FP8 das Training von DeepSeek-V3 optimiert.",
        "visual_description": {
          "concept": "FP8 Mixed Precision",
          "description": "Ein stilisiertes GPU-Chip-Symbol, auf dem 'FP8' prominent platziert ist. Pfeile zeigen von 'FP8' zu 'Schnelleres Training' und 'Weniger GPU-Speicher'.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Rolle und die Vorteile des FP8 Mixed Precision Trainings in DeepSeek-V3 erkl√§ren k√∂nnen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "FP8 Mixed Precision Training",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein stilisiertes GPU-Chip-Symbol, auf dem 'FP8' prominent platziert ist. Pfeile zeigen von 'FP8' zu 'Schnelleres Training' und 'Weniger GPU-Speicher'."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Vorteile bietet das FP8 Mixed Precision Training in DeepSeek-V3?",
          "options": [
            "Erh√∂hte Modellgenauigkeit",
            "Beschleunigtes Training und reduzierter GPU-Speicherverbrauch",
            "Verbesserte menschliche Pr√§ferenz-Ausrichtung",
            "L√§ngere Kontextl√§ngen"
          ],
          "correct_answer": 1,
          "explanation": "Das FP8 Mixed Precision Training erm√∂glicht beschleunigtes Training und reduziert den GPU-Speicherverbrauch."
        }
      },
      {
        "id": "micro_5",
        "title": "DualPipe & Kommunikationsoptimierung",
        "knowledge_md": "Wie √ºberwindet DeepSeek-V3 Kommunikationsengp√§sse beim Training? üîó Das Modell nutzt den DualPipe-Algorithmus f√ºr effiziente Pipeline-Parallelit√§t, der Pipeline-Bubbles reduziert und Kommunikation durch √úberlappung mit Berechnungen verbirgt. Effiziente Cross-Node All-to-All Kommunikations-Kernels sind ebenfalls integriert.",
        "visual_title": "Kommunikations-Meister",
        "visual_description_text": "Verstehe, wie DeepSeek-V3 die Kommunikation beim Training optimiert.",
        "visual_description": {
          "concept": "DualPipe & All-to-All",
          "description": "Eine Darstellung einer Datenpipeline mit zwei parallelen Str√§ngen ('DualPipe'), die fl√ºssig ineinander √ºbergehen, um 'Bubbles' zu vermeiden. Ein Symbol f√ºr 'Computation-Communication Overlap' ist sichtbar. Zus√§tzlich sind Netzwerksymbole mit Pfeilen zwischen Knoten ('Cross-Node All-to-All') zu sehen.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Methoden zur √úberwindung von Kommunikationsengp√§ssen (DualPipe, All-to-All Kernels) im Training von DeepSeek-V3 beschreiben.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "graph",
          "structure": {
            "nodes": [
              {
                "id": "center",
                "label": "DualPipe & Kommunikationsoptimierung"
              },
              {
                "id": "aspect1",
                "label": "Aspekt 1"
              },
              {
                "id": "aspect2",
                "label": "Aspekt 2"
              },
              {
                "id": "aspect3",
                "label": "Aspekt 3"
              }
            ],
            "edges": [
              {
                "from": "center",
                "to": "aspect1"
              },
              {
                "from": "center",
                "to": "aspect2"
              },
              {
                "from": "center",
                "to": "aspect3"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Darstellung einer Datenpipeline mit zwei parallelen Str√§ngen ('DualPipe'), die fl√ºssig ineinander √ºbergehen, um 'Bubbles' zu vermeiden. Ein Symbol f√ºr 'Computation-Communication Overlap' ist sichtbar. Zus√§tzlich sind Netzwerksymbole mit Pfeilen zwischen Knoten ('Cross-Node All-to-All') zu sehen."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Was ist der Hauptvorteil des DualPipe-Algorithmus in DeepSeek-V3?",
          "options": [
            "Erh√∂hung der Modellparameter",
            "Reduzierung von Pipeline-Bubbles und Verbergen von Kommunikation",
            "Destillation von Reasoning-F√§higkeiten",
            "Verbesserung der menschlichen Pr√§ferenz-Ausrichtung"
          ],
          "correct_answer": 1,
          "explanation": "Der DualPipe-Algorithmus hat weniger Pipeline-Bubbles und verbirgt den Gro√üteil der Kommunikation w√§hrend des Trainings durch Computation-Communication Overlap."
        }
      },
      {
        "id": "micro_6",
        "title": "Stabiles Vortraining von DeepSeek-V3",
        "knowledge_md": "Wie wird DeepSeek-V3 √ºberhaupt trainiert? üìö DeepSeek-V3 wird auf 14.8 Billionen hochwertigen und diversen Tokens vortrainiert. Dieser Prozess ist bemerkenswert stabil; es gab w√§hrend des gesamten Trainingsprozesses keine nicht behebbaren Verlusteinbr√ºche oder Rollbacks.",
        "visual_title": "Pre-Training Prozess",
        "visual_description_text": "Visualisiere den Umfang und die Stabilit√§t des Vortrainings.",
        "visual_description": {
          "concept": "Pre-Training",
          "description": "Eine gro√üe Datenwolke oder ein Stapel von 'Tokens', die in einen Trichter flie√üen, der zu einem 'DeepSeek-V3'-Modell f√ºhrt. Ein 'Stabilit√§ts-Indikator' (z.B. eine gerade Linie auf einem Diagramm) zeigt die Stabilit√§t des Prozesses an.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Menge der Daten und die Stabilit√§t des Vortrainingsprozesses von DeepSeek-V3 kennen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Stabiles Vortraining von DeepSeek-V3",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine gro√üe Datenwolke oder ein Stapel von 'Tokens', die in einen Trichter flie√üen, der zu einem 'DeepSeek-V3'-Modell f√ºhrt. Ein 'Stabilit√§ts-Indikator' (z.B. eine gerade Linie auf einem Diagramm) zeigt die Stabilit√§t des Prozesses an."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Auf wie vielen Tokens wird DeepSeek-V3 vortrainiert?",
          "options": [
            "32K",
            "128K",
            "14.8 Billionen",
            "671 Milliarden"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 wird auf 14.8T (Billionen) hochwertigen und diversen Tokens vortrainiert."
        }
      },
      {
        "id": "micro_7",
        "title": "Kontext & Post-Training",
        "knowledge_md": "Was passiert nach dem Vortraining von DeepSeek-V3? üß† Nach dem Vortraining erfolgt eine zweistufige Kontextl√§ngenerweiterung auf bis zu 128K. Anschlie√üend wird ein Post-Training durchgef√ºhrt, inklusive Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL), um das Modell an menschliche Pr√§ferenzen anzupassen.",
        "visual_title": "Nach dem Vortraining",
        "visual_description_text": "Verfolge den Weg von DeepSeek-V3 nach dem initialen Training.",
        "visual_description": {
          "concept": "Kontext & Post-Training",
          "description": "Eine Zeitleiste oder ein Flussdiagramm, das 'Pre-Training' zu 'Kontextl√§ngenerweiterung (32K -> 128K)' und dann zu 'Post-Training (SFT & RL)' f√ºhrt. Ein Gehirnsymbol mit Pfeilen von 'DeepSeek-R1' zu 'DeepSeek-V3' symbolisiert die Wissensdestillation.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Phasen der Kontextl√§ngenerweiterung und des Post-Trainings (SFT, RL, Wissensdestillation) von DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "timeline",
          "structure": {
            "timeline": {
              "title": "Kontext & Post-Training",
              "sections": [
                {
                  "period": "Phase 1",
                  "events": [
                    "Einf√ºhrung",
                    "Grundlagen"
                  ]
                },
                {
                  "period": "Phase 2",
                  "events": [
                    "Vertiefung",
                    "Anwendung"
                  ]
                },
                {
                  "period": "Phase 3",
                  "events": [
                    "Meisterschaft",
                    "Integration"
                  ]
                }
              ]
            }
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Zeitleiste oder ein Flussdiagramm, das 'Pre-Training' zu 'Kontextl√§ngenerweiterung (32K -> 128K)' und dann zu 'Post-Training (SFT & RL)' f√ºhrt. Ein Gehirnsymbol mit Pfeilen von 'DeepSeek-R1' zu 'DeepSeek-V3' symbolisiert die Wissensdestillation."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Methoden werden im Post-Training von DeepSeek-V3 angewendet?",
          "options": [
            "Nur Pre-Training",
            "Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL)",
            "FP8 Mixed Precision Training",
            "Multi-Token Prediction (MTP)"
          ],
          "correct_answer": 1,
          "explanation": "Das Post-Training umfasst Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL)."
        }
      },
      {
        "id": "micro_8",
        "title": "Die Kosten von DeepSeek-V3",
        "knowledge_md": "Wie viel kostet es, ein Modell wie DeepSeek-V3 zu trainieren? üí∞ Die gesamten Trainingskosten von DeepSeek-V3 belaufen sich auf 2.788 Millionen H800 GPU-Stunden. Bei einem angenommenen Mietpreis von 2 $ pro GPU-Stunde entspricht das insgesamt nur 5.576 Millionen US-Dollar.",
        "visual_title": "Trainingskosten im √úberblick",
        "visual_description_text": "Erfahre, wie sich die Gesamtkosten f√ºr das Training von DeepSeek-V3 zusammensetzen.",
        "visual_description": {
          "concept": "Trainingskosten",
          "description": "Ein Kreisdiagramm oder eine gestapelte Balkengrafik, die die Aufschl√ºsselung der Trainingskosten zeigt: 'Pre-Training (2664K GPU Stunden)', 'Kontextl√§ngenerweiterung (119K GPU Stunden)', 'Post-Training (5K GPU Stunden)'. Die Gesamtkosten in USD ($5.576M) sind prominent dargestellt.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Gesamtkosten und deren Aufschl√ºsselung f√ºr das Training von DeepSeek-V3 nachvollziehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Die Kosten von DeepSeek-V3",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Kreisdiagramm oder eine gestapelte Balkengrafik, die die Aufschl√ºsselung der Trainingskosten zeigt: 'Pre-Training (2664K GPU Stunden)', 'Kontextl√§ngenerweiterung (119K GPU Stunden)', 'Post-Training (5K GPU Stunden)'. Die Gesamtkosten in USD ($5.576M) sind prominent dargestellt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie hoch sind die Gesamtkosten f√ºr das Training von DeepSeek-V3 in US-Dollar, basierend auf dem angenommenen Mietpreis?",
          "options": [
            "2.788 Millionen",
            "5.328 Millionen",
            "0.238 Millionen",
            "5.576 Millionen"
          ],
          "correct_answer": 3,
          "explanation": "Die Gesamtkosten belaufen sich auf 5.576 Millionen US-Dollar, basierend auf 2.788M GPU-Stunden und einem Mietpreis von 2 $ pro GPU-Stunde."
        }
      },
      {
        "id": "micro_9",
        "title": "DeepSeek-V3: Leistung & Benchmarks",
        "knowledge_md": "Ist DeepSeek-V3 wirklich so leistungsstark, wie es klingt? üèÜ DeepSeek-V3-Base ist das derzeit st√§rkste Open-Source-Basismodell, besonders in Code und Mathematik. Die Chat-Version √ºbertrifft andere Open-Source-Modelle und ist vergleichbar mit f√ºhrenden Closed-Source-Modellen wie GPT-4o und Claude-3.5-Sonnet.",
        "visual_title": "Leistungsvergleich",
        "visual_description_text": "Sieh, wie DeepSeek-V3 im Vergleich zu anderen Modellen abschneidet.",
        "visual_description": {
          "concept": "Modellleistung",
          "description": "Eine Rangliste oder ein Balkendiagramm, das DeepSeek-V3-Base als 'st√§rkstes Open-Source-Basismodell' hervorhebt, insbesondere in 'Code' und 'Mathematik'. Die Chat-Version wird mit 'GPT-4o' und 'Claude-3.5-Sonnet' verglichen, um die Vergleichbarkeit darzustellen.",
          "interaction_type": "click_explore",
          "learning_goal": "Die herausragende Leistung von DeepSeek-V3 im Vergleich zu anderen Open-Source- und Closed-Source-Modellen erkennen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "DeepSeek-V3: Leistung & Benchmarks",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Rangliste oder ein Balkendiagramm, das DeepSeek-V3-Base als 'st√§rkstes Open-Source-Basismodell' hervorhebt, insbesondere in 'Code' und 'Mathematik'. Die Chat-Version wird mit 'GPT-4o' und 'Claude-3.5-Sonnet' verglichen, um die Vergleichbarkeit darzustellen."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "In welchen Bereichen ist DeepSeek-V3-Base besonders stark?",
          "options": [
            "Sprach√ºbersetzung und Bilderkennung",
            "Code und Mathematik",
            "Musikkomposition und Videobearbeitung",
            "Datenanalyse und Tabellenkalkulation"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3-Base ist das derzeit st√§rkste Open-Source-Basismodell, besonders in Code und Mathematik."
        }
      }
    ],
    "metadata": {
      "original_pdf_chapters_count": 1,
      "total_micros_generated": 9
    }
  },
  "metadata": {
    "source_file": "temp\\cc511e86-128f-44e8-813e-0427ad30ffaa.pdf",
    "generation_date": "2025-06-09T12:00:31.926236",
    "source_filename": "cc511e86-128f-44e8-813e-0427ad30ffaa"
  }
}