{
  "knowledge_extraction": {
    "format_version": "2.0",
    "micros": [
      {
        "id": "micro_1",
        "title": "DeepSeek-V3: Ein Open-Source LLM",
        "knowledge_md": "Wusstest du, dass sich Large Language Models (LLMs) rasant entwickeln? üöÄ DeepSeek-V3 ist ein gro√ües Mixture-of-Experts (MoE) Modell mit beeindruckenden 671 Milliarden Parametern, von denen 37 Milliarden pro Token aktiviert werden. Es ist ein f√ºhrendes Open-Source-Modell, das darauf abzielt, die L√ºcke zu Closed-Source-Modellen zu schlie√üen.",
        "visual_title": "LLM-Evolution",
        "visual_description_text": "Erkunde die Entwicklung von LLMs und die Rolle von DeepSeek-V3.",
        "visual_description": {
          "concept": "LLM Evolution",
          "description": "Eine Zeitachse, die die schnelle Entwicklung von LLMs zeigt, mit Hervorhebung von DeepSeek-V3 als Open-Source-MoE-Modell. Zeige, wie es sich zu Closed-Source-Modellen wie GPT-4o und Claude-3.5-Sonnet positioniert.",
          "interaction_type": "click_explore",
          "learning_goal": "Verstehen, was DeepSeek-V3 ist und seine Position im LLM-√ñkosystem.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "timeline",
          "structure": {
            "timeline": {
              "title": "DeepSeek-V3: Ein Open-Source LLM",
              "sections": [
                {
                  "period": "Phase 1",
                  "events": [
                    "Einf√ºhrung",
                    "Grundlagen"
                  ]
                },
                {
                  "period": "Phase 2",
                  "events": [
                    "Vertiefung",
                    "Anwendung"
                  ]
                },
                {
                  "period": "Phase 3",
                  "events": [
                    "Meisterschaft",
                    "Integration"
                  ]
                }
              ]
            }
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Zeitachse, die die schnelle Entwicklung von LLMs zeigt, mit Hervorhebung von DeepSeek-V3 als Open-Source-MoE-Modell. Zeige, wie es sich zu Closed-Source-Modellen wie GPT-4o und Claude-3.5-Sonnet positioniert."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Was ist DeepSeek-V3 haupts√§chlich?",
          "options": [
            "Ein kleines Sprachmodell",
            "Ein Closed-Source-Modell",
            "Ein gro√ües Mixture-of-Experts (MoE) Modell",
            "Ein reines Bilderkennungsmodell"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 ist ein gro√ües Mixture-of-Experts (MoE) Modell mit 671B Parametern, das als Open-Source-Modell entwickelt wurde."
        }
      },
      {
        "id": "micro_2",
        "title": "Effiziente Architektur: MLA & DeepSeekMoE",
        "knowledge_md": "Wie bleibt DeepSeek-V3 trotz seiner Gr√∂√üe so effizient? ü§î Es nutzt Multi-head Latent Attention (MLA) f√ºr schnelle Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training. Diese bew√§hrten Architekturen wurden bereits in DeepSeek-V2 erfolgreich eingesetzt.",
        "visual_title": "Architektur-Grundlagen",
        "visual_description_text": "Visualisiere die Kernarchitekturen von DeepSeek-V3.",
        "visual_description": {
          "concept": "MLA & DeepSeekMoE",
          "description": "Ein Diagramm, das MLA und DeepSeekMoE als Kernkomponenten der DeepSeek-V3-Architektur darstellt, mit kurzen Beschreibungen ihrer Funktionen (effiziente Inferenz, kosteng√ºnstiges Training).",
          "interaction_type": "click_explore",
          "learning_goal": "Die zwei Hauptarchitekturen von DeepSeek-V3 und ihre Vorteile verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Effiziente Architektur: MLA & DeepSeekMoE",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Diagramm, das MLA und DeepSeekMoE als Kernkomponenten der DeepSeek-V3-Architektur darstellt, mit kurzen Beschreibungen ihrer Funktionen (effiziente Inferenz, kosteng√ºnstiges Training)."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Architekturen sorgen f√ºr Effizienz in DeepSeek-V3?",
          "options": [
            "Transformer und RNNs",
            "MLA und DeepSeekMoE",
            "CNNs und GANs",
            "LSTM und GRU"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 nutzt Multi-head Latent Attention (MLA) f√ºr effiziente Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training."
        }
      },
      {
        "id": "micro_3",
        "title": "Innovatives Lastenbalancing: Ohne Hilfsverlust",
        "knowledge_md": "Stell dir vor, du k√∂nntest die Leistung deines Modells verbessern, ohne Kompromisse einzugehen! ‚ú® DeepSeek-V3 ist Vorreiter einer hilfsverlustfreien Strategie f√ºr das Lastenbalancing. Das Ziel ist es, die negativen Auswirkungen auf die Modellleistung zu minimieren, die sonst bei Lastenbalancing-Bem√ºhungen entstehen k√∂nnen.",
        "visual_title": "Lastenbalancing-Innovation",
        "visual_description_text": "Verstehe die Vorteile der neuen Lastenbalancing-Strategie.",
        "visual_description": {
          "concept": "Auxiliary-loss-free Load Balancing",
          "description": "Ein Vergleichsdiagramm, das traditionelles Lastenbalancing mit Hilfsverlusten und die neue hilfsverlustfreie Strategie von DeepSeek-V3 zeigt, um den Vorteil der minimierten Leistungsbeeintr√§chtigung zu verdeutlichen.",
          "interaction_type": "click_explore",
          "learning_goal": "Die innovative Lastenbalancing-Strategie von DeepSeek-V3 und ihren Nutzen erkennen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Innovatives Lastenbalancing: Ohne Hilfsverlust",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Vergleichsdiagramm, das traditionelles Lastenbalancing mit Hilfsverlusten und die neue hilfsverlustfreie Strategie von DeepSeek-V3 zeigt, um den Vorteil der minimierten Leistungsbeeintr√§chtigung zu verdeutlichen."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Was ist das Ziel der hilfsverlustfreien Strategie f√ºr Lastenbalancing?",
          "options": [
            "Die Trainingszeit zu verl√§ngern",
            "Negative Auswirkungen auf die Modellleistung zu minimieren",
            "Den Speicherverbrauch zu erh√∂hen",
            "Die Modellgr√∂√üe zu reduzieren"
          ],
          "correct_answer": 1,
          "explanation": "Die hilfsverlustfreie Strategie f√ºr Lastenbalancing zielt darauf ab, die negativen Auswirkungen auf die Modellleistung zu minimieren."
        }
      },
      {
        "id": "micro_4",
        "title": "Multi-Token Prediction (MTP) Training",
        "knowledge_md": "Willst du wissen, wie DeepSeek-V3 seine Gesamtleistung steigert? üìà Es setzt ein Multi-Token Prediction (MTP) Trainingsziel ein. Es wurde beobachtet, dass dies die Gesamtleistung auf Bewertungsbenchmarks erheblich verbessert. MTP kann zudem f√ºr spekulatives Decoding zur Inferenzbeschleunigung genutzt werden.",
        "visual_title": "MTP-Vorteile",
        "visual_description_text": "Erfahre, wie MTP die Modellleistung verbessert.",
        "visual_description": {
          "concept": "Multi-Token Prediction Objective",
          "description": "Eine Infografik, die den Prozess der Multi-Token Prediction darstellt und ihre Auswirkungen auf die Modellleistung und Inferenzbeschleunigung (spekulatives Decoding) hervorhebt.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Rolle des Multi-Token Prediction Trainingsziels f√ºr die Modellleistung verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Multi-Token Prediction (MTP) Training",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Infografik, die den Prozess der Multi-Token Prediction darstellt und ihre Auswirkungen auf die Modellleistung und Inferenzbeschleunigung (spekulatives Decoding) hervorhebt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wof√ºr kann das Multi-Token Prediction (MTP) Ziel verwendet werden?",
          "options": [
            "Nur f√ºr die Datenvorbereitung",
            "Zur Verbesserung der Gesamtleistung und f√ºr spekulatives Decoding",
            "Ausschlie√ülich zur Reduzierung der Modellgr√∂√üe",
            "Nur f√ºr die Visualisierung von Daten"
          ],
          "correct_answer": 1,
          "explanation": "Das Multi-Token Prediction (MTP) Ziel verbessert die Gesamtleistung auf Benchmarks und kann f√ºr spekulatives Decoding zur Inferenzbeschleunigung genutzt werden."
        }
      },
      {
        "id": "micro_5",
        "title": "Effizientes Training mit FP8 Mixed Precision",
        "knowledge_md": "Wie trainiert man riesige Modelle effizient? üí° DeepSeek-V3 unterst√ºtzt FP8 Mixed Precision Training. Diese vielversprechende L√∂sung beschleunigt das Training und reduziert den GPU-Speicherverbrauch erheblich. Die Wirksamkeit von FP8-Training wurde hier erstmals an einem extrem gro√üskaligen Modell validiert.",
        "visual_title": "FP8-Training im Fokus",
        "visual_description_text": "Entdecke die Vorteile von FP8 Mixed Precision Training.",
        "visual_description": {
          "concept": "FP8 Mixed Precision Training",
          "description": "Ein Diagramm, das den Unterschied zwischen Standard- und FP8-Training zeigt, mit Fokus auf die Reduzierung des Speicherbedarfs und die Beschleunigung des Trainings. Zeige die Validierung an einem gro√üen Modell.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Bedeutung und Vorteile von FP8 Mixed Precision Training f√ºr DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Effizientes Training mit FP8 Mixed Precision",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Diagramm, das den Unterschied zwischen Standard- und FP8-Training zeigt, mit Fokus auf die Reduzierung des Speicherbedarfs und die Beschleunigung des Trainings. Zeige die Validierung an einem gro√üen Modell."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Vorteile bietet FP8 Mixed Precision Training?",
          "options": [
            "Erh√∂hten GPU-Speicherverbrauch",
            "Verlangsamtes Training",
            "Beschleunigtes Training und reduzierten GPU-Speicherverbrauch",
            "Nur f√ºr kleine Modelle geeignet"
          ],
          "correct_answer": 2,
          "explanation": "FP8 Mixed Precision Training beschleunigt das Training und reduziert den GPU-Speicherverbrauch."
        }
      },
      {
        "id": "micro_6",
        "title": "DualPipe Algorithmus & Kommunikation",
        "knowledge_md": "Effizientes Training braucht clevere Algorithmen! ‚öôÔ∏è DeepSeek-V3 nutzt den DualPipe-Algorithmus f√ºr effiziente Pipeline-Parallelisierung. Dieser Algorithmus reduziert Pipeline-Bubbles und verbirgt den Gro√üteil der Kommunikation w√§hrend des Trainings durch Computation-Communication Overlap. Das erm√∂glicht es, auch bei steigender Modellgr√∂√üe feink√∂rnige Experten √ºber Knoten hinweg zu nutzen, ohne nennenswerten Kommunikations-Overhead.",
        "visual_title": "DualPipe-Effizienz",
        "visual_description_text": "Visualisiere, wie DualPipe die Kommunikation optimiert.",
        "visual_description": {
          "concept": "DualPipe Algorithm",
          "description": "Ein Flussdiagramm oder eine Animation, die den DualPipe-Algorithmus und das Konzept des Computation-Communication Overlap veranschaulicht, um zu zeigen, wie Kommunikationsengp√§sse vermieden werden.",
          "interaction_type": "click_explore",
          "learning_goal": "Verstehen, wie der DualPipe-Algorithmus die Trainingseffizienz verbessert.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "DualPipe Algorithmus & Kommunikation",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Flussdiagramm oder eine Animation, die den DualPipe-Algorithmus und das Konzept des Computation-Communication Overlap veranschaulicht, um zu zeigen, wie Kommunikationsengp√§sse vermieden werden."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Was ist ein Vorteil des DualPipe-Algorithmus?",
          "options": [
            "Er erh√∂ht die Pipeline-Bubbles",
            "Er versteckt Kommunikation durch Computation-Communication Overlap",
            "Er ist nur f√ºr kleine Modelle geeignet",
            "Er ben√∂tigt keine Parallelisierung"
          ],
          "correct_answer": 1,
          "explanation": "Der DualPipe-Algorithmus versteckt den Gro√üteil der Kommunikation w√§hrend des Trainings durch Computation-Communication Overlap."
        }
      },
      {
        "id": "micro_7",
        "title": "Stabiles Vortraining & Kontextl√§nge",
        "knowledge_md": "Ein stabiles Training ist Gold wert! ‚ú® Der Vortrainingsprozess von DeepSeek-V3 war bemerkenswert stabil. Es gab keine irreversiblen Verlustspitzen oder Rollbacks. Anschlie√üend wurde die maximale Kontextl√§nge in zwei Stufen erweitert: zuerst auf 32K und dann weiter auf beeindruckende 128K.",
        "visual_title": "Trainingsstabilit√§t & Skalierung",
        "visual_description_text": "Erkunde die Stabilit√§t und Kontextl√§ngenerweiterung des Trainings.",
        "visual_description": {
          "concept": "Pre-training Stability & Context Extension",
          "description": "Eine Grafik, die die Stabilit√§t des Trainingsverlaufs ohne Verlustspitzen darstellt und die zweistufige Erweiterung der Kontextl√§nge von 32K auf 128K visualisiert.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Stabilit√§t des Vortrainings und die Erweiterung der Kontextl√§nge von DeepSeek-V3 nachvollziehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Stabiles Vortraining & Kontextl√§nge",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Grafik, die die Stabilit√§t des Trainingsverlaufs ohne Verlustspitzen darstellt und die zweistufige Erweiterung der Kontextl√§nge von 32K auf 128K visualisiert."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie wurde die Kontextl√§nge von DeepSeek-V3 erweitert?",
          "options": [
            "In einer einzigen Stufe auf 128K",
            "Gar nicht",
            "In zwei Stufen, zuerst auf 32K, dann auf 128K",
            "Nur auf 32K"
          ],
          "correct_answer": 2,
          "explanation": "Die Kontextl√§nge wurde in zwei Stufen erweitert: zuerst auf 32K, dann auf 128K."
        }
      },
      {
        "id": "micro_8",
        "title": "Post-Training: SFT, RL & Wissenstransfer",
        "knowledge_md": "Wie wird ein Modell menschlicher und leistungsf√§higer? üß† Nach dem Vortraining durchl√§uft DeepSeek-V3 ein Post-Training mit Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL). Ziel ist die Ausrichtung an menschlichen Pr√§ferenzen und die Freisetzung seines vollen Potenzials. Dabei wird die Reasoning-F√§higkeit aus den DeepSeek-R1-Modellen destilliert, w√§hrend Genauigkeit und Generierungsl√§nge ausbalanciert werden.",
        "visual_title": "Post-Training-Prozess",
        "visual_description_text": "Verstehe die Schritte nach dem Vortraining.",
        "visual_description": {
          "concept": "Post-training & Knowledge Distillation",
          "description": "Ein Flussdiagramm, das die Phasen des Post-Trainings (SFT, RL) und den Prozess der Wissensdestillation von DeepSeek-R1-Modellen in DeepSeek-V3 darstellt.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Post-Training-Schritte und die Wissensdestillation in DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Post-Training: SFT, RL & Wissenstransfer",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Ein Flussdiagramm, das die Phasen des Post-Trainings (SFT, RL) und den Prozess der Wissensdestillation von DeepSeek-R1-Modellen in DeepSeek-V3 darstellt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Methoden werden im Post-Training von DeepSeek-V3 angewendet?",
          "options": [
            "Nur Vortraining",
            "Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL)",
            "Ausschlie√ülich manuelle Anpassung",
            "Nur Datenbereinigung"
          ],
          "correct_answer": 1,
          "explanation": "Im Post-Training werden Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL) angewendet."
        }
      },
      {
        "id": "micro_9",
        "title": "Wirtschaftliche Trainingskosten & Leistung",
        "knowledge_md": "Hohe Leistung muss nicht teuer sein! üí∞ DeepSeek-V3 zeichnet sich durch seine wirtschaftlichen Trainingskosten aus. Das Vortraining auf 14.8 Billionen Tokens kostete nur 2.664 Millionen H800 GPU-Stunden. Die Gesamtkosten f√ºr das volle Training belaufen sich auf 2.788 Millionen GPU-Stunden, was bei einem Mietpreis von 2 USD pro GPU-Stunde etwa 5.576 Millionen USD entspricht.",
        "visual_title": "Kosten-Leistungs-Verh√§ltnis",
        "visual_description_text": "Erkunde die beeindruckenden Kosten und die Leistung von DeepSeek-V3.",
        "visual_description": {
          "concept": "Training Costs & Performance",
          "description": "Eine Infografik, die die Trainingskosten (GPU-Stunden, USD) von DeepSeek-V3 im Vergleich zu seiner Leistung als st√§rkstes Open-Source-Basismodell (besonders in Code und Mathematik) darstellt.",
          "interaction_type": "click_explore",
          "learning_goal": "Die wirtschaftlichen Trainingskosten und die hohe Leistung von DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Wirtschaftliche Trainingskosten & Leistung",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Infografik, die die Trainingskosten (GPU-Stunden, USD) von DeepSeek-V3 im Vergleich zu seiner Leistung als st√§rkstes Open-Source-Basismodell (besonders in Code und Mathematik) darstellt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie hoch waren die gesch√§tzten Gesamttrainingskosten von DeepSeek-V3 in USD?",
          "options": [
            "√úber 10 Millionen USD",
            "Unter 1 Million USD",
            "Etwa 5.576 Millionen USD",
            "Nicht im Text erw√§hnt"
          ],
          "correct_answer": 2,
          "explanation": "Die gesch√§tzten Gesamttrainingskosten von DeepSeek-V3 betragen etwa 5.576 Millionen USD."
        }
      }
    ],
    "metadata": {
      "original_pdf_chapters_count": 1,
      "total_micros_generated": 9
    }
  },
  "metadata": {
    "source_file": "temp\\472261e3-965e-473e-8442-fee6b331de80.pdf",
    "generation_date": "2025-06-09T13:01:02.420451",
    "source_filename": "472261e3-965e-473e-8442-fee6b331de80"
  }
}