{
  "knowledge_extraction": {
    "format_version": "2.0",
    "micros": [
      {
        "id": "micro_1",
        "title": "LLM-Evolution und Open-Source-Fortschritt",
        "knowledge_md": "Hast du dich gefragt, wie schnell sich KI entwickelt? üöÄ Gro√üe Sprachmodelle (LLMs) machen riesige Fortschritte und kommen der K√ºnstlichen Allgemeinen Intelligenz (AGI) immer n√§her. Auch Open-Source-Modelle holen stark auf. Reihen wie LLaMA, Qwen und Mistral zeigen, wie Open-Source-LLMs die L√ºcke zu Closed-Source-Modellen schlie√üen.",
        "visual_title": "LLMs auf dem Vormarsch",
        "visual_description_text": "Erkunde die Entwicklung von LLMs.",
        "visual_description": {
          "concept": "LLM Evolution",
          "description": "Eine Zeitlinie, die die schnelle Entwicklung von LLMs und die Ann√§herung an AGI darstellt. Hervorhebung von Closed-Source- und Open-Source-Modellen, die die L√ºcke schlie√üen. Beispiele f√ºr Open-Source-Modelle wie LLaMA, Qwen, Mistral.",
          "interaction_type": "click_explore",
          "learning_goal": "Die schnelle Entwicklung von LLMs und den Fortschritt von Open-Source-Modellen verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "LLM-Evolution und Open-Source-Fortschritt",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Zeitlinie, die die schnelle Entwicklung von LLMs und die Ann√§herung an AGI darstellt. Hervorhebung von Closed-Source- und Open-Source-Modellen, die die L√ºcke schlie√üen. Beispiele f√ºr Open-Source-Modelle wie LLaMA, Qwen, Mistral."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welches Ziel verfolgen Open-Source-LLMs laut Text?",
          "options": [
            "Die Entwicklung von AGI stoppen",
            "Die L√ºcke zu Closed-Source-Modellen schlie√üen",
            "Nur f√ºr wissenschaftliche Zwecke genutzt werden",
            "Neue Hardware entwickeln"
          ],
          "correct_answer": 1,
          "explanation": "Open-Source-Modelle wie LLaMA und Qwen machen gro√üe Fortschritte, um die L√ºcke zu ihren Closed-Source-Gegenst√ºcken zu schlie√üen."
        }
      },
      {
        "id": "micro_2",
        "title": "DeepSeek-V3: Ein MoE-Gigant",
        "knowledge_md": "Neugierig auf die n√§chste Generation von Open-Source-LLMs? ‚ú® DeepSeek-V3 ist ein riesiges Mixture-of-Experts (MoE) Modell, das die Grenzen offener Modelle verschiebt. Es ist mit 671 Milliarden Parametern ausgestattet. F√ºr jedes Token werden nur 37 Milliarden Parameter aktiviert, was es effizient macht, trotz seiner enormen Gr√∂√üe.",
        "visual_title": "DeepSeek-V3: MoE-Architektur",
        "visual_description_text": "Entdecke die Skalierung von DeepSeek-V3.",
        "visual_description": {
          "concept": "DeepSeek-V3 MoE",
          "description": "Eine Infografik, die DeepSeek-V3 als MoE-Modell mit 671B Gesamtparametern darstellt. Ein Highlight zeigt, dass 37B Parameter pro Token aktiviert werden.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Definition und Skalierung von DeepSeek-V3 als MoE-Modell verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "DeepSeek-V3: Ein MoE-Gigant",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Infografik, die DeepSeek-V3 als MoE-Modell mit 671B Gesamtparametern darstellt. Ein Highlight zeigt, dass 37B Parameter pro Token aktiviert werden."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele Parameter werden in DeepSeek-V3 pro Token aktiviert?",
          "options": [
            "671 Milliarden",
            "37 Milliarden",
            "14.8 Billionen",
            "5.576 Millionen"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 hat 671 Milliarden Parameter insgesamt, aber nur 37 Milliarden werden f√ºr jedes Token aktiviert."
        }
      },
      {
        "id": "micro_3",
        "title": "Effizienz durch Architektur: MLA & DeepSeekMoE",
        "knowledge_md": "Wie erreicht DeepSeek-V3 so viel Leistung bei geringen Kosten? üí° DeepSeek-V3 nutzt bew√§hrte Architekturen wie Multi-head Latent Attention (MLA) f√ºr effiziente Inferenz und DeepSeekMoE f√ºr kosteng√ºnstiges Training. Diese Technologien wurden bereits in DeepSeek-V2 validiert und sorgen f√ºr robuste Leistung bei gleichzeitig hoher Effizienz.",
        "visual_title": "DeepSeek-V3 Kernarchitekturen",
        "visual_description_text": "Klicke auf die Architekturen, um ihre Funktion zu sehen.",
        "visual_description": {
          "concept": "MLA & DeepSeekMoE",
          "description": "Zwei Symbole oder Bl√∂cke, die MLA und DeepSeekMoE repr√§sentieren. Beim Anklicken werden ihre jeweiligen Vorteile (effiziente Inferenz, kosteng√ºnstiges Training) und die Validierung in DeepSeek-V2 angezeigt.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Rolle von MLA und DeepSeekMoE in DeepSeek-V3 f√ºr Effizienz verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Effizienz durch Architektur: MLA & DeepSeekMoE",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei Symbole oder Bl√∂cke, die MLA und DeepSeekMoE repr√§sentieren. Beim Anklicken werden ihre jeweiligen Vorteile (effiziente Inferenz, kosteng√ºnstiges Training) und die Validierung in DeepSeek-V2 angezeigt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Architektur wird in DeepSeek-V3 f√ºr kosteng√ºnstiges Training verwendet?",
          "options": [
            "Multi-head Latent Attention (MLA)",
            "DeepSeekMoE",
            "FP8 Mixed Precision",
            "DualPipe"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeekMoE wird f√ºr kosteng√ºnstiges Training eingesetzt, w√§hrend MLA f√ºr effiziente Inferenz dient."
        }
      },
      {
        "id": "micro_4",
        "title": "Innovative Strategien: Lastenausgleich & Multi-Token Prediction",
        "knowledge_md": "Was macht DeepSeek-V3 noch leistungsf√§higer? üöÄ DeepSeek-V3 f√ºhrt zwei neue Strategien ein: eine hilfsverlustfreie Methode f√ºr den Lastenausgleich, um Leistungseinbu√üen zu minimieren, und ein Multi-Token Prediction Trainingsziel. Das Multi-Token Prediction Ziel verbessert die Gesamtleistung auf Bewertungs-Benchmarks.",
        "visual_title": "DeepSeek-V3: Neue Strategien",
        "visual_description_text": "Entdecke die innovativen Verbesserungen.",
        "visual_description": {
          "concept": "Neue Strategien",
          "description": "Zwei Icons, eines f√ºr 'Lastenausgleich (hilfsverlustfrei)' und eines f√ºr 'Multi-Token Prediction'. Klicke auf jedes, um die Beschreibung zu sehen, wie sie die Modellf√§higkeiten verbessern.",
          "interaction_type": "click_explore",
          "learning_goal": "Die zwei zus√§tzlichen Strategien zur Leistungssteigerung in DeepSeek-V3 kennenlernen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Innovative Strategien: Lastenausgleich & Multi-Token Prediction",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Zwei Icons, eines f√ºr 'Lastenausgleich (hilfsverlustfrei)' und eines f√ºr 'Multi-Token Prediction'. Klicke auf jedes, um die Beschreibung zu sehen, wie sie die Modellf√§higkeiten verbessern."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche neue Strategie minimiert Leistungseinbu√üen beim Lastenausgleich in DeepSeek-V3?",
          "options": [
            "Multi-Token Prediction",
            "Hilfsverlustfreie Strategie",
            "FP8 Mixed Precision",
            "DualPipe Algorithmus"
          ],
          "correct_answer": 1,
          "explanation": "DeepSeek-V3 setzt eine hilfsverlustfreie Strategie f√ºr den Lastenausgleich ein, um negative Auswirkungen auf die Modellleistung zu minimieren."
        }
      },
      {
        "id": "micro_5",
        "title": "FP8 Mixed Precision Training",
        "knowledge_md": "M√∂chtest du wissen, wie DeepSeek-V3 so effizient trainiert wird? ‚ö° DeepSeek-V3 nutzt FP8 Mixed Precision Training, eine vielversprechende L√∂sung f√ºr effizientes Training. Dies wurde erstmals bei einem extrem gro√üen Modell validiert. Durch FP8-Berechnung und -Speicherung werden sowohl das Training beschleunigt als auch der GPU-Speicherverbrauch reduziert.",
        "visual_title": "FP8 Training",
        "visual_description_text": "Erfahre mehr √ºber effizientes Training.",
        "visual_description": {
          "concept": "FP8 Mixed Precision Training",
          "description": "Eine Grafik, die den Unterschied zwischen Standard- und FP8-Pr√§zision darstellt, mit Fokus auf die Vorteile: beschleunigtes Training und reduzierter GPU-Speicherverbrauch.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Vorteile und die Anwendung von FP8 Mixed Precision Training in DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "FP8 Mixed Precision Training",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Grafik, die den Unterschied zwischen Standard- und FP8-Pr√§zision darstellt, mit Fokus auf die Vorteile: beschleunigtes Training und reduzierter GPU-Speicherverbrauch."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Vorteile bietet FP8 Mixed Precision Training in DeepSeek-V3?",
          "options": [
            "Erh√∂hte Modellgr√∂√üe und Komplexit√§t",
            "Beschleunigtes Training und reduzierter GPU-Speicherverbrauch",
            "Verbesserte menschliche Pr√§ferenzen",
            "L√§ngere Kontextl√§ngen"
          ],
          "correct_answer": 1,
          "explanation": "FP8 Mixed Precision Training erm√∂glicht beschleunigtes Training und reduziert den GPU-Speicherverbrauch."
        }
      },
      {
        "id": "micro_6",
        "title": "DualPipe und Kommunikationseffizienz",
        "knowledge_md": "Wie √ºberwindet DeepSeek-V3 Kommunikationsengp√§sse beim Training? üîó Der DualPipe-Algorithmus erm√∂glicht effiziente Pipeline-Parallelit√§t, indem er Kommunikationszeiten durch √úberlappung mit Berechnungen verbirgt. Dies f√ºhrt zu nahezu null All-to-All-Kommunikations-Overhead, selbst bei der Skalierung des Modells √ºber Knoten hinweg.",
        "visual_title": "DualPipe-Algorithmus",
        "visual_description_text": "Sieh, wie Kommunikation optimiert wird.",
        "visual_description": {
          "concept": "DualPipe Algorithm",
          "description": "Eine Animation oder Grafik, die den DualPipe-Algorithmus darstellt, wie er Pipeline-Bubbles reduziert und Kommunikation durch Berechnung-Kommunikation-√úberlappung verbirgt.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Funktionsweise des DualPipe-Algorithmus und seine Rolle bei der Kommunikationseffizienz verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "DualPipe und Kommunikationseffizienz",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Animation oder Grafik, die den DualPipe-Algorithmus darstellt, wie er Pipeline-Bubbles reduziert und Kommunikation durch Berechnung-Kommunikation-√úberlappung verbirgt."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Was ist ein Hauptvorteil des DualPipe-Algorithmus in DeepSeek-V3?",
          "options": [
            "Erh√∂ht die Anzahl der Modellparameter",
            "Versteckt Kommunikation durch Berechnung-Kommunikation-√úberlappung",
            "Verl√§ngert die Trainingszeit",
            "F√ºhrt zu irreversiblen Verlustspitzen"
          ],
          "correct_answer": 1,
          "explanation": "Der DualPipe-Algorithmus verbirgt die meiste Kommunikation w√§hrend des Trainings durch Berechnung-Kommunikation-√úberlappung."
        }
      },
      {
        "id": "micro_7",
        "title": "Stabilit√§t und Skalierung des Pre-Trainings",
        "knowledge_md": "Stell dir vor: 14,8 Billionen Tokens trainieren ‚Äì und das ohne Probleme! üìà DeepSeek-V3 wurde auf einer riesigen Menge von 14,8 Billionen hochwertigen Tokens vortrainiert. Der Prozess war bemerkenswert stabil. Es gab w√§hrend des gesamten Pre-Trainings keine irreversiblen Verlustspitzen oder Notwendigkeit zum Rollback.",
        "visual_title": "Pre-Training Stabilit√§t",
        "visual_description_text": "Erlebe die Robustheit des Trainings.",
        "visual_description": {
          "concept": "Pre-Training Stability",
          "description": "Eine Grafik, die den stabilen Verlauf des Pre-Trainings √ºber 14.8T Tokens darstellt, ohne Verlustspitzen oder Rollbacks.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Stabilit√§t und das Ausma√ü des Pre-Trainings von DeepSeek-V3 erfassen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Stabilit√§t und Skalierung des Pre-Trainings",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Grafik, die den stabilen Verlauf des Pre-Trainings √ºber 14.8T Tokens darstellt, ohne Verlustspitzen oder Rollbacks."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Wie viele Tokens wurden f√ºr das Pre-Training von DeepSeek-V3 verwendet?",
          "options": [
            "37 Milliarden",
            "671 Milliarden",
            "14.8 Billionen",
            "128K"
          ],
          "correct_answer": 2,
          "explanation": "DeepSeek-V3 wurde auf 14.8 Billionen hochwertigen Tokens vortrainiert."
        }
      },
      {
        "id": "micro_8",
        "title": "Post-Training und Kontextl√§nge",
        "knowledge_md": "Wie wird DeepSeek-V3 noch besser und vielseitiger? üß† Nach dem Pre-Training wird die Kontextl√§nge in zwei Stufen auf bis zu 128K erweitert. Anschlie√üend erfolgt das Post-Training mittels SFT und RL. Dabei wird die Denkf√§higkeit von DeepSeek-R1-Modellen destilliert, um DeepSeek-V3 an menschliche Pr√§ferenzen anzupassen.",
        "visual_title": "Post-Training & Kontext",
        "visual_description_text": "Verstehe die letzten Schritte der Modellentwicklung.",
        "visual_description": {
          "concept": "Post-Training & Context Extension",
          "description": "Eine Infografik, die den zweistufigen Prozess der Kontextl√§ngenerweiterung (32K -> 128K) und die Post-Training-Schritte (SFT, RL, Knowledge Distillation von DeepSeek-R1) visualisiert.",
          "interaction_type": "click_explore",
          "learning_goal": "Die Bedeutung und die Methoden des Post-Trainings und der Kontextl√§ngenerweiterung von DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "Post-Training und Kontextl√§nge",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Infografik, die den zweistufigen Prozess der Kontextl√§ngenerweiterung (32K -> 128K) und die Post-Training-Schritte (SFT, RL, Knowledge Distillation von DeepSeek-R1) visualisiert."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Welche Methoden werden im Post-Training von DeepSeek-V3 angewendet?",
          "options": [
            "Nur Pre-Training",
            "Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL)",
            "Nur Kontextl√§ngenerweiterung",
            "Ausschlie√ülich Knowledge Distillation"
          ],
          "correct_answer": 1,
          "explanation": "Das Post-Training von DeepSeek-V3 umfasst Supervised Fine-Tuning (SFT) und Reinforcement Learning (RL), sowie Knowledge Distillation."
        }
      },
      {
        "id": "micro_9",
        "title": "DeepSeek-V3: Kosten und Leistung",
        "knowledge_md": "Kann ein Top-LLM wirklich kosteng√ºnstig sein? üí∞ DeepSeek-V3 zeichnet sich durch seine wirtschaftlichen Trainingskosten aus, die durch optimiertes Co-Design von Algorithmen, Frameworks und Hardware erreicht werden. Die Gesamtkosten f√ºr das Training belaufen sich auf nur 5,576 Millionen US-Dollar, was es zum st√§rksten Open-Source-Basismodell macht.",
        "visual_title": "Kosten-Effizienz von DeepSeek-V3",
        "visual_description_text": "Erfahre mehr √ºber die beeindruckende Kosten-Leistungs-Bilanz.",
        "visual_description": {
          "concept": "Training Costs & Performance",
          "description": "Eine Darstellung der Gesamttrainingskosten ($5.576M) und der Leistung von DeepSeek-V3 als st√§rkstes Open-Source-Basismodell (besonders in Code und Mathematik) und vergleichbar mit GPT-4o/Claude-3.5-Sonnet.",
          "interaction_type": "click_explore",
          "learning_goal": "Die wirtschaftlichen Trainingskosten und die f√ºhrende Leistung von DeepSeek-V3 verstehen.",
          "fixed_dimensions": {
            "width": 1024,
            "height": 768
          }
        },
        "visual_specification": {
          "mermaid_type": "flowchart",
          "structure": {
            "nodes": [
              {
                "id": "start",
                "label": "Start",
                "shape": "circle"
              },
              {
                "id": "main",
                "label": "DeepSeek-V3: Kosten und Leistung",
                "shape": "rect"
              },
              {
                "id": "detail1",
                "label": "Details",
                "shape": "diamond"
              },
              {
                "id": "end",
                "label": "Verstanden!",
                "shape": "circle"
              }
            ],
            "connections": [
              {
                "from": "start",
                "to": "main",
                "label": ""
              },
              {
                "from": "main",
                "to": "detail1",
                "label": "erkunden"
              },
              {
                "from": "detail1",
                "to": "end",
                "label": "gelernt"
              }
            ]
          },
          "styling": {
            "theme": "dark",
            "primary_color": "#7F5AF0",
            "secondary_color": "#2CB67D",
            "accent_color": "#FBB040",
            "background_color": "#16213E",
            "text_color": "#E4E6EA"
          },
          "interactivity": {
            "type": "click_explore",
            "hover_effects": true,
            "click_actions": true,
            "animations": true
          },
          "dimensions": {
            "width": 1024,
            "height": 768
          },
          "ready_to_render": true,
          "fallback_description": "Eine Darstellung der Gesamttrainingskosten ($5.576M) und der Leistung von DeepSeek-V3 als st√§rkstes Open-Source-Basismodell (besonders in Code und Mathematik) und vergleichbar mit GPT-4o/Claude-3.5-Sonnet."
        },
        "has_mini_quiz": true,
        "mini_quiz": {
          "question": "Was sind die gesch√§tzten Gesamttrainingskosten f√ºr DeepSeek-V3 laut Text?",
          "options": [
            "$2 pro GPU-Stunde",
            "$0.238 Millionen",
            "$5.576 Millionen",
            "$2.788 Millionen"
          ],
          "correct_answer": 2,
          "explanation": "Die Gesamttrainingskosten f√ºr DeepSeek-V3 belaufen sich auf 5.576 Millionen US-Dollar."
        }
      }
    ],
    "metadata": {
      "original_pdf_chapters_count": 1,
      "total_micros_generated": 9
    }
  },
  "metadata": {
    "source_file": "temp\\2d854b48-a8b0-4e54-b8aa-b6c7178441ea.pdf",
    "generation_date": "2025-06-09T14:56:56.542820",
    "source_filename": "2d854b48-a8b0-4e54-b8aa-b6c7178441ea"
  }
}